{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: Could not find a suitable TLS CA certificate bundle, invalid path: C:\\Program Files\\PostgreSQL\\16\\ssl\\certs\\ca-bundle.crt\n",
      "\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "! pip install pandoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONDITIONAL GAN\n",
    "\n",
    "## NOTA\n",
    "Como esta práctica se escapaba a mi comprensión , para hacerla me he ayudado de recursos en internet como documentación, paginas web, y asistentes de IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyrjJP7MqpAN"
   },
   "source": [
    "En esta práctica deberéis implementar una GAN condicional con el dataset FashionMNIST.\n",
    "\n",
    "Podéis basaros en este ejemplo: https://keras.io/examples/generative/conditional_gan/.\n",
    "\n",
    "Lo único que debéis cambiar es la entrada, tanto del G como del D, para incluir la clase que queréis asociar con la imagen generada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9kHiRJtwBDs",
    "outputId": "4a17096d-befa-43e8-c25f-fcec805fdda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# montamos la unidad drive donde tenemos los datos en la carpeta drive/My Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "8bCnkVIwrJz8"
   },
   "outputs": [],
   "source": [
    "# importamos las librerías necesarias\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Concatenate, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINIENDO EL DISCRIMINADOR: MODELO FUNCIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7y3jZ4gVrMAz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 784)                  1568      ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 784)                  0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 28, 28, 1)            0         ['leaky_re_lu_7[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 28, 28, 2)            0         ['input_8[0][0]',             \n",
      " )                                                                   'reshape_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 128)          2432      ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 14, 14, 128)          0         ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 128)            147584    ['leaky_re_lu_8[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 7, 7, 128)            0         ['conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 6272)                 0         ['leaky_re_lu_9[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 6272)                 0         ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 1)                    6273      ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 157857 (616.63 KB)\n",
      "Trainable params: 157857 (616.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# definimos el discriminador: en este caso va a ser convolucional\n",
    "def define_discriminator(in_shape=(28, 28, 1), n_classes=10):\n",
    "\n",
    "    # creamos la entrada de la información condicional\n",
    "    in_label = Input(shape=(1,))                            # el input de la etiqueta\n",
    "    mapping_cond_inf = Embedding(n_classes, 50)             # embedding de input categórico \n",
    "    \n",
    "    \"\"\"\n",
    "    # debemos añadir una capa densa que nos transforme el escalar que representa\n",
    "    # nuestra clase a una imagen de (28, 28) para luego poder concatenar esa \n",
    "    # información con la imagen\n",
    "    \"\"\"\n",
    "    n_nodes = in_shape[0]*in_shape[1]\n",
    "    mapping_cond_inf = Dense(n_nodes)(in_label)\n",
    "    mapping_cond_inf = LeakyReLU(alpha= 0.1)(mapping_cond_inf)\n",
    "    mapping_cond_inf = Reshape((in_shape[0], in_shape[1], 1))(mapping_cond_inf)\n",
    "\n",
    "   \n",
    "    in_image = Input(shape=in_shape)                                  # entrada de la imagen de 28x28\n",
    "    merge = Concatenate()([in_image, mapping_cond_inf])               # concatenamos la info condicional con la imagen\n",
    "\n",
    "    # downsample\n",
    "    fe = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(merge)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    # downsample\n",
    "    fe = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    fe = Flatten()(fe)\n",
    "    fe = Dropout(0.4)(fe)\n",
    "    out_layer = Dense(1, activation='sigmoid')(fe) \n",
    "    \n",
    "    model = Model([in_image, in_label], out_layer)               # definimos el modelo\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)                            # optimizador adam\n",
    "\n",
    "    # compilamos\n",
    "    model.compile(loss='binary_crossentropy',                    # output binario real o fake                    \n",
    "                  optimizer=opt, metrics=['accuracy'])           # metrica: accuracy\n",
    "    return model\n",
    "\n",
    "discriminador = define_discriminator()\n",
    "discriminador.summary()\n",
    "plot_model(define_discriminator(), to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINIENDO EL GENERADOR: MODELO FUNCIONAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "nucb657PrT_R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_42 (InputLayer)       [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " input_41 (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " dense_40 (Dense)            (None, 6272)                 633472    ['input_42[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_20 (Embedding)    (None, 1, 50)                500       ['input_41[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_58 (LeakyReLU)  (None, 6272)                 0         ['dense_40[0][0]']            \n",
      "                                                                                                  \n",
      " dense_39 (Dense)            (None, 1, 49)                2499      ['embedding_20[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_27 (Reshape)        (None, 7, 7, 128)            0         ['leaky_re_lu_58[0][0]']      \n",
      "                                                                                                  \n",
      " reshape_26 (Reshape)        (None, 7, 7, 1)              0         ['dense_39[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenat  (None, 7, 7, 129)            0         ['reshape_27[0][0]',          \n",
      " e)                                                                  'reshape_26[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_12 (Conv2  (None, 14, 14, 128)          264320    ['concatenate_20[0][0]']      \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " leaky_re_lu_59 (LeakyReLU)  (None, 14, 14, 128)          0         ['conv2d_transpose_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_13 (Conv2  (None, 28, 28, 128)          262272    ['leaky_re_lu_59[0][0]']      \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " leaky_re_lu_60 (LeakyReLU)  (None, 28, 28, 128)          0         ['conv2d_transpose_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 28, 28, 1)            6273      ['leaky_re_lu_60[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1169336 (4.46 MB)\n",
      "Trainable params: 1169336 (4.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# definimos el generador\n",
    "def define_generator(latent_dim= 100, n_classes=10):\n",
    "    \n",
    "    # creamos la entrada de la información condicional\n",
    "    in_label = Input(shape=(1,))\n",
    "    emb = Embedding(n_classes, 50)(in_label)\n",
    "    n_nodes = 7 * 7\n",
    "    mapping_cond_inf = Dense(n_nodes)(emb)\n",
    "    mapping_cond_inf = Reshape((7, 7, 1))(mapping_cond_inf)\n",
    "\n",
    "\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "\n",
    "    # número de dimensiones para poder tratar con él con nuestra CNN\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    gen = Dense(n_nodes)(in_lat)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((7, 7, 128))(gen)\n",
    "\n",
    "    \n",
    "    merge = Concatenate()([gen, mapping_cond_inf])                           # concatenamos el código latente y la información\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)  # aumentamos a 14x14\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)                                          # activación\n",
    "    \n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)    # aumentamos a 28x28\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)                                          # activación \n",
    "    \n",
    "    out_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)     # salida del modelo (una imagen en escala de grises de 28x28)\n",
    "    model = Model([in_lat, in_label], out_layer)                             # definimos el modelo\n",
    "    return model\n",
    "\n",
    "define_generator().summary()\n",
    "plot_model(define_discriminator(), to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINIENDO LA GAN, MODELO FUNCIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0CKU8au2sfY9"
   },
   "outputs": [],
   "source": [
    "# definimos el modelo GAN combinando generador y discriminador, para entrenar el generador\n",
    "def define_gan(g_model, d_model):\n",
    "\n",
    "    d_model.trainable = False\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    gen_output = g_model.output\n",
    "    \n",
    "    gan_output = d_model([gen_output, gen_label])\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    \n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "plot_model(define_gan(), to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGANDO - GENERANDO IMÁGENES REALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acd2xBRrs1Sm"
   },
   "outputs": [],
   "source": [
    "# definimos las funciones para cargar el MNIST\n",
    "def load_real_samples():\n",
    "    from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "    \n",
    "    (trainX, trainY), (_, _) = load_data()     # cargamos el dataset - ESTA VEZ QUEREMOS LAS IMÁGENES Y LAS CLASES\n",
    "    X = np.expand_dims(trainX, axis=-1)        # expandimos la dimensión del batch\n",
    "    X = X.astype('float32')                    # convertimos a float32\n",
    "    X = (X - 127.5) / 127.5                    # escalamos entre -1 y 1\n",
    "    return X, trainY                           # devolvemos tanto las imágenes como las clases\n",
    "\n",
    "\"\"\"\n",
    "# nos creamos una función que nos devuelva n_samples del dataset (imagen, clase) \n",
    "# y generamos las etiquetas de entrenamiento GAN: 1 \n",
    "\"\"\"\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    \n",
    "    images, labels = dataset                               # separamos las imágenes de las etiquetas\n",
    "    ix = np.random.randint(0, images.shape[0], n_samples)  # seleccionamos n_samples muestras aleatoriamente\n",
    "    X, labels = images[ix], labels[ix]                     # las cogemos junto a su correspondiente clase\n",
    "    y = np.ones((n_samples, 1))                            # generamos las etiquetas para entrenar la GAN (1)\n",
    "\n",
    "    return (X, labels), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ittsv-4U_sVp"
   },
   "source": [
    "## GENERANDO IMÁGENES FALSAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0o9oAmXgs61c"
   },
   "outputs": [],
   "source": [
    "# generamos los vectores latentes que introduciremos al generador\n",
    "def generate_latent_points(latent_dim, batch_size, n_classes=10):\n",
    "    # batch_size es el número de elementos por batch \n",
    "    # latent_dim es la dimensión del vector latente\n",
    "    \n",
    "    x_input = np.random.randn(latent_dim * batch_size)   # generamos un vector de batch_size * latent_dim números aleatorios\n",
    "    z_input = x_input.reshape(batch_size, latent_dim)    # redimensionamos el vector para que tenga un tamaño (batch_size, latent_dim)\n",
    "    labels = np.random.randint(low= 0,\n",
    "                               high= n_classes, \n",
    "                               size= batch_size)\n",
    "    return z_input, labels                               # el vector de ruido como la \"clase\": z_input y labels\n",
    " \n",
    "# creamos datos fake con el generador (dinero falsificado)\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples): \n",
    "     \n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples) # usamos la función anterior para generar los vectores latentes\n",
    "    images = g_model.predict([z_input, labels_input])                     # le introducimos los vectores latentes y las clases al generador\n",
    "    y = np.zeros(shape= (n_samples, 1))                                   # etiqueta 0 porque utilizaremos esta función para el discriminador\n",
    "    \"\"\"    \n",
    "    # debemos devolver, por un lado, images y labels_inputs (para condicionar la GAN), \n",
    "    # y por el otro, la etiqueta que le asignamos: en este caso, al estar\n",
    "    # entrenando el generador, etiqueta = 0\n",
    "    \"\"\"\n",
    "    return [images, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihC0sltV2URE"
   },
   "outputs": [],
   "source": [
    "# función para guardar las imágenes generadas\n",
    "def save_plot(examples, epoch, n=10, figsize=(20, 20)):\n",
    "    examples = (examples * 127.5) + 127.5\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
    "    # guardamos las imágenes\n",
    "    filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINIENDO EL ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vBkSW8WH2Zzz"
   },
   "outputs": [],
   "source": [
    "# función para entrenar la GAN: el discriminador y el generador\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for epoch in range(n_epochs):               # bucle para las epochs\n",
    "        for batch in range(bat_per_epo):        # bucle para los batch\n",
    "            \n",
    "            \"\"\"\n",
    "            # vamos a separar las pérdidas del discriminador\n",
    "            # cuando le metemos imágenes reales y cuando le metemos imágenes\n",
    "            # fake para ver cómo lo hace con cada tipo\n",
    "            # lo ideal es que llegue a un 50% de acc en cada uno\n",
    "            \"\"\"\n",
    "\n",
    "            \n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)              # preparamos los datos reales\n",
    "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)                      # actualizamos el discriminador\n",
    "            \n",
    "            [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)  # generamos datos falsos\n",
    "            d_loss2, _ = d_model.train_on_batch([X_fake, labels_fake], y_fake)                      # actualizamos el discriminador\n",
    "\t\t\t\n",
    "             \n",
    "            \n",
    "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)   # preparamos los puntos en el espacio latente:\n",
    "            \n",
    "            \"\"\"\n",
    "            # creamos etiquetas invertidas para el generador: utilizamos el D(x) \n",
    "            # para que piense que las muestras que le introducimos son reales, y\n",
    "            # en caso de que diga que no son reales, aprovechamos la información\n",
    "            # de sus gradientes para actualizar el G(z) para que la próxima vez\n",
    "            # los datos generados por G(z) sean más parecidos a los reales\n",
    "            \"\"\"\n",
    "            y_gan = np.ones( shape= (n_batch, 1))     # un vector columna del tamaño del batch_size con todo unos\n",
    "            \n",
    "            \"\"\"\n",
    "            # entrenamos el generador de forma que actualice\n",
    "            # sus pesos usando los gradientes del discriminador\n",
    "            # en este modelo (gan_model) el discriminador está\n",
    "            # congelado, por lo que no se actualizan sus pesos: \n",
    "            # no queremos \"untar\" a nuestro policía, lo que queremos \n",
    "            # es fabricar dinero más realista.\n",
    "            \"\"\"\n",
    "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "\n",
    "            # mostramos el progreso\n",
    "            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % \n",
    "                  (epoch+1, batch+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "        # evaluamos el desempeño del modelo cada 10 épocas\n",
    "        if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "            # preparamos los datos reales\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "            # evaluamos el discriminador con datos reales\n",
    "            _, acc_real = d_model.evaluate([X_real, labels_real], y_real, verbose=0)\n",
    "            # preparamos ejemplos fake\n",
    "            [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, n_batch)\n",
    "            # evaluamos el discriminador con datos fake\n",
    "            _, acc_fake = d_model.evaluate([X_fake, labels_fake], y_fake, verbose=0)\n",
    "            # mostramos cómo de bueno es nuestro policía\n",
    "            print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "            # guardamos las imágenes generadas\n",
    "            save_plot(X_fake, epoch)\n",
    "            # guardamos el generador para tenerlo disponible más tarde\n",
    "            filename = 'cgan_generator_model_%03d.h5' % (epoch + 1)\n",
    "            g_model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREANDO Y ENTRENANDO EL MODELO CONDITIONAL GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkIcUyas2Zz2"
   },
   "outputs": [],
   "source": [
    "\n",
    "latent_dim = 100                         # size of the latent space\n",
    "d_model = define_discriminator()         # create the discriminator\n",
    "g_model = define_generator(latent_dim)   # create the generator\n",
    "gan_model = define_gan(g_model, d_model) # create the gan\n",
    "dataset = load_real_samples()            # load image data\n",
    "# train model\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9LXaAVb4Rri"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw1lSh5JwBc1"
   },
   "outputs": [],
   "source": [
    "# los guardamos en nuestro drive para evitar tener que reejecutar cada vez\n",
    "!mkdir drive/My\\ Drive/7_cond_dcgan_fashionmnist\n",
    "!cp *gen* drive/My\\ Drive/7_cond_dcgan_fashionmnist/\n",
    "!ls -lah drive/My\\ Drive/7_cond_dcgan_fashionmnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQitNcy-Cjgn"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(plt.imread('generated_plot_e001.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ez8QfGI4UjH"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(plt.imread('generated_plot_e010.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dixkDKlF4pXX"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(plt.imread('generated_plot_e100.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l57oPvHkv6De"
   },
   "outputs": [],
   "source": [
    "# vamos a generar imágenes de una determinada clase\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# cargamos el modelo\n",
    "model = load_model('cgan_generator_model_100.h5')\n",
    "# generate images\n",
    "latent_points, labels = generate_latent_points(100, 100)\n",
    "# specify labels\n",
    "labels = np.asarray([x for _ in range(10) for x in range(10)])\n",
    "# generate images\n",
    "X  = model.predict([latent_points, labels])\n",
    "# scale from [-1,1] to [0,1]\n",
    "X = (X + 1) / 2.0\n",
    "# plot the result\n",
    "save_plot(X, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvmbBfixwxgL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(plt.imread('generated_plot_e101.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HATtkwaJxbF4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GANs_condicionales_FashionMNIST_Práctica.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
