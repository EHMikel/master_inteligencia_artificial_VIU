{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsE4-Q5RQTPJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51d4b843-6e79-421e-90f0-ea9c1f7960b9"
      },
      "source": [
        "# SOLO PARA USO EN GOOGLE COLABORATORY\n",
        "# para conectar el notebook con la cuenta de gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!ls \"/content/drive/My Drive/\"\n",
        "BASE_FOLDER = '/content/drive/MyDrive/VIU/Docencia/MIAR_04_2021-22/07MAIR/' # Se debe garantizar que la carpeta docencia compartida se almacena en el directorio raíz de Google Drive. En caso contrario modificar este path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTUDtR1WkBfp",
        "outputId": "c286555d-dd42-40ff-df8e-2c391324f742"
      },
      "source": [
        "!ls \"/content/drive/MyDrive/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'[07MAIR_04_A_2018-19] Actividad1_corrección_1conv'\n",
            " 07MIAR_PracticaObservacional\n",
            " 07MIAR_Proyecto_Programacion\n",
            "'Actividad 1'\n",
            "'Cesión Derechos Imagen VIU.docx'\n",
            "'Colab Notebooks'\n",
            "'Docentes MAIR'\n",
            " HOLA.gdoc\n",
            " MAIR_MARKETING\n",
            " Panel_12_05_2020\n",
            " Redes_Neuronales.ipynb\n",
            " TFM_LauraVelaSampedro_21042021.pdf\n",
            " VIU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB36wZd_tf-v"
      },
      "source": [
        "## Functional API\n",
        "- Hasta ahora hemos desarrollado redes neuronales secuenciales\n",
        "- Suficiente para muchos contextos, limitante para otros más complejos\n",
        " - Inputs independientes, múltiples outputs, ramificaciones internas, skip connections, retroalimentaciones, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_zPvc73tmE3"
      },
      "source": [
        "#### Ejemplo X input <-> 1 output: Predicción de precio de ropa de segunda mano\n",
        "\n",
        "- Inputs: metadata marca, tiempo usado (one hot encoded), foto (imagen), descripción (texto).\n",
        "- Modelo con tres submodelos (MLP para metadata, RNN para descripción a partir de texto, CNN para imagen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an8JNVGGtsBw"
      },
      "source": [
        "#### Ejemplo 1 input <-> X output: predicción de año de publicación y estilo de un libro\n",
        "\n",
        "- Un módulo con dos outputs (clasificadores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7N2m2n6t0q9"
      },
      "source": [
        "- Desventajas de la alternativa de construir modelos separados:\n",
        " - Coste computacional tanto en entrenamiento como en inferencia\n",
        " - No se tiene en cuenta toda la información a la vez y analizar la información de manera independiente produce sesgo\n",
        " - Se pierden las ventajas de un modelo entrenable end-to-end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-AG85ARE2rc"
      },
      "source": [
        "# Empleando la functional API: Red MISO CNN+MLP en HOUSE DATASET\n",
        "\n",
        "- Modelo con dos inputs (atributos y fotos)\n",
        "- Output: precio de las casas\n",
        "\n",
        "https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lObBVS9ahpuy"
      },
      "source": [
        "### Mis funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9yNNQPHE-c7"
      },
      "source": [
        "# import the necessary packages\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Filtrar las casas de codigos postales poco populares (menos de 10 casas)\n",
        "MIN_HOUSES_PER_ZIPCODE = 20\n",
        "# dimensiones de las imagenes (downsampling)\n",
        "IMAGE_DIM = (32,32)\n",
        "\n",
        "# Cargar los atributos del dataset\n",
        "def load_house_attributes(inputPath):\n",
        "        # Cargar el dataset con nombres especificados\n",
        "        cols = [\"bedrooms\", \"bathrooms\", \"area\", \"zipcode\", \"price\"]\n",
        "        df = pd.read_csv(inputPath, sep=\" \", header=None, names=cols)\n",
        "\n",
        "        # filtrar codigos postales con pocas casas\n",
        "        zipcodes = df[\"zipcode\"].value_counts().keys().tolist()\n",
        "        counts = df[\"zipcode\"].value_counts().tolist()\n",
        "\n",
        "        for (zipcode, count) in zip(zipcodes, counts):\n",
        "            if count < MIN_HOUSES_PER_ZIPCODE:\n",
        "                idxs = df[df[\"zipcode\"] == zipcode].index\n",
        "                df.drop(idxs, inplace=True)\n",
        "\n",
        "        return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZK3gW_SGBgn"
      },
      "source": [
        "# Procesar los atributos\n",
        "def process_house_attributes(df, train, test):\n",
        "        # normalizar (valores 0 a 1) atributos continuos\n",
        "        continuous = [\"bedrooms\", \"bathrooms\", \"area\"]\n",
        "        cs = MinMaxScaler()\n",
        "        trainContinuous = cs.fit_transform(train[continuous])\n",
        "        testContinuous = cs.transform(test[continuous])\n",
        "\n",
        "        # one-hot encode el codigo postal\n",
        "        zipBinarizer = LabelBinarizer().fit(df[\"zipcode\"])\n",
        "        trainCategorical = zipBinarizer.transform(train[\"zipcode\"])\n",
        "        testCategorical = zipBinarizer.transform(test[\"zipcode\"])\n",
        "\n",
        "        # unir todos los atributos y dividir dataset\n",
        "        trainX = np.hstack([trainCategorical, trainContinuous])\n",
        "        testX = np.hstack([testCategorical, testContinuous])\n",
        "\n",
        "        return (trainX, testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfcnGa0pGF7n"
      },
      "source": [
        "# Cargar imagenes\n",
        "def load_house_images(df, inputPath):\n",
        "        images = []\n",
        "\n",
        "        # cada linea es un data point\n",
        "        for i in df.index.values:\n",
        "            # cargar las cuatro imagenes por casa\n",
        "            basePath = os.path.sep.join([inputPath, \"{}_*\".format(i + 1)])\n",
        "            housePaths = sorted(list(glob.glob(basePath)))\n",
        "            inputImages = []\n",
        "            outputImage = np.zeros((IMAGE_DIM[0] * 2, IMAGE_DIM[1] * 2, 3), dtype=\"uint8\")\n",
        "\n",
        "            # por cada imagen, redimensionar\n",
        "            for housePath in housePaths:\n",
        "                # load the input image, resize it to be 32 32, and then\n",
        "                # update the list of input images\n",
        "                image = cv2.imread(housePath)\n",
        "                image = cv2.resize(image, IMAGE_DIM)\n",
        "                inputImages.append(image)\n",
        "\n",
        "            # tile the four input images in the output image such the first\n",
        "            # image goes in the top-right corner, the second image in the\n",
        "            # top-left corner, the third image in the bottom-right corner,\n",
        "            # and the final image in the bottom-left corner\n",
        "            outputImage[0:IMAGE_DIM[0], 0:IMAGE_DIM[1]] = inputImages[0]\n",
        "            outputImage[0:IMAGE_DIM[0], IMAGE_DIM[1]:IMAGE_DIM[1]*2] = inputImages[1]\n",
        "            outputImage[IMAGE_DIM[0]:IMAGE_DIM[0]*2, IMAGE_DIM[1]:IMAGE_DIM[1]*2] = inputImages[2]\n",
        "            outputImage[IMAGE_DIM[0]:IMAGE_DIM[0]*2, 0:IMAGE_DIM[1]] = inputImages[3]\n",
        "\n",
        "            # add the tiled image to our set of images the network will be\n",
        "            # trained on\n",
        "            images.append(outputImage)\n",
        "\n",
        "        # return our set of images\n",
        "        return np.array(images) / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJPLyKg1hV_r"
      },
      "source": [
        "### Creando la rama MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmIRpa5fGYAg"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, BatchNormalization, MaxPooling2D, Activation, concatenate\n",
        "\n",
        "# Creacion del modelo MLP (para los atributos numericos)\n",
        "def create_mlp(dim, regress=False):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
        "        model.add(Dense(4, activation=\"relu\"))\n",
        "\n",
        "        # check to see if the regression node should be added\n",
        "        if regress:\n",
        "            model.add(Dense(1, activation=\"linear\"))\n",
        "\n",
        "        # return our model\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeCaiPyshaoz"
      },
      "source": [
        "### Creando la rama CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGY7noznGogF"
      },
      "source": [
        "# Crear el modelo CNN\n",
        "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n",
        "        inputShape = (height, width, depth)\n",
        "        chanDim = -1\n",
        "\n",
        "        # define the model input\n",
        "        inputs = Input(shape=inputShape)\n",
        "\n",
        "        # crear tantas capas como filtros pasados\n",
        "        for (i, f) in enumerate(filters):\n",
        "            if i == 0:\n",
        "                x = inputs\n",
        "\n",
        "            # CONV => RELU => BN => POOL\n",
        "            x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
        "            x = Activation(\"relu\")(x)\n",
        "            x = BatchNormalization(axis=chanDim)(x)\n",
        "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Top model\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(16)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = BatchNormalization(axis=chanDim)(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "\n",
        "        # Middle output layer\n",
        "        x = Dense(4)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "\n",
        "        # Check to see if the regression node should be added\n",
        "        if regress:\n",
        "            x = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "        model = Model(inputs, x)\n",
        "\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IcPheskgcKQ"
      },
      "source": [
        "### Importando datos desde Google Drive: House Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zfKWikTiCb-"
      },
      "source": [
        "# SOLO PARA USO EN GOOGLE COLABORATORY\n",
        "# para conectar el notebook con la cuenta de gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "#!ls \"/content/drive/My Drive/\"\n",
        "BASE_FOLDER = '/content/drive/My Drive/07MAIR_0420/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhTYmtLgG3E0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d2804f93-767d-4769-a6e6-6a30048cd31b"
      },
      "source": [
        "# Cargar los atributos numericos\n",
        "print('Cargando atributoss...')\n",
        "inputPath = BASE_FOLDER+'resources/Houses-dataset/HousesInfo.txt'\n",
        "df = load_house_attributes(inputPath)\n",
        "\n",
        "# Cargar imágenes\n",
        "print(\"[INFO] loading house images...\")\n",
        "images = load_house_images(df, BASE_FOLDER+'resources/Houses-dataset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cargando atributoss...\n",
            "[INFO] loading house images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNgo41fUk8L6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de1f25a1-7416-43cf-8da7-be8144989c99"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(384, 64, 64, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLOEcvWNhQMO"
      },
      "source": [
        "### Acondicionamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zMlkb-9G3_K"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir imagenes en train y test\n",
        "split = train_test_split(df, images, test_size=0.25, random_state=42)\n",
        "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
        "\n",
        "# Normalizar el precio de las casas\n",
        "maxPrice = trainAttrX[\"price\"].max()\n",
        "trainY = trainAttrX[\"price\"] / maxPrice\n",
        "testY = testAttrX[\"price\"] / maxPrice\n",
        "\n",
        "# Procesar atributos numericos\n",
        "(trainAttrX, testAttrX) = process_house_attributes(df,trainAttrX, testAttrX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59jasLBQgWzG"
      },
      "source": [
        "### Construcción del modelo híbrido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5GXRNtoG6yK"
      },
      "source": [
        "# Crear los dos modelos (MLP y CNN)\n",
        "mlp = create_mlp(trainAttrX.shape[1], regress=False)\n",
        "cnn = create_cnn(IMAGE_DIM[0] * 2, IMAGE_DIM[1]*2, 3, regress=False)\n",
        "\n",
        "# Unir ambas ramas en una única de salida (concatenarlos)\n",
        "combinedInput = concatenate([mlp.output, cnn.output])\n",
        "\n",
        "# Clasificador final tras la concatenacion\n",
        "x = Dense(4, activation=\"relu\")(combinedInput)\n",
        "x = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "# Construir el modelo final\n",
        "model = Model(inputs=[mlp.input, cnn.input], outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG8rTrv9f3MJ"
      },
      "source": [
        "### Compilación y entrenamiento de nuestra red MISO híbrida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LnUfijxG9pH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc848a2f-8bdf-4c16-8257-fdb380aa8479"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# utilizamos el optimizador Adam (con learning rate adaptativo)\n",
        "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
        "\n",
        "# entrenar\n",
        "print(\"Entrenar el modelo...\")\n",
        "H = model.fit([trainAttrX, trainImagesX], trainY,\n",
        "        validation_data=([testAttrX, testImagesX], testY),\n",
        "        epochs=50, batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entrenar el modelo...\n",
            "Train on 288 samples, validate on 96 samples\n",
            "Epoch 1/50\n",
            "288/288 [==============================] - 4s 12ms/sample - loss: 1058.0105 - val_loss: 697.4843\n",
            "Epoch 2/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 702.0007 - val_loss: 220.6218\n",
            "Epoch 3/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 619.5501 - val_loss: 224.6528\n",
            "Epoch 4/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 446.5802 - val_loss: 241.4039\n",
            "Epoch 5/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 343.1163 - val_loss: 213.5732\n",
            "Epoch 6/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 307.4464 - val_loss: 143.5633\n",
            "Epoch 7/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 216.2664 - val_loss: 168.7331\n",
            "Epoch 8/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 237.6755 - val_loss: 181.7929\n",
            "Epoch 9/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 171.1048 - val_loss: 123.7346\n",
            "Epoch 10/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 161.3895 - val_loss: 123.0261\n",
            "Epoch 11/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 161.1767 - val_loss: 129.7954\n",
            "Epoch 12/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 149.7940 - val_loss: 97.8922\n",
            "Epoch 13/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 111.5875 - val_loss: 80.3869\n",
            "Epoch 14/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 101.5946 - val_loss: 83.0598\n",
            "Epoch 15/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 118.2108 - val_loss: 67.3131\n",
            "Epoch 16/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 97.6585 - val_loss: 69.3508\n",
            "Epoch 17/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 105.3505 - val_loss: 74.3702\n",
            "Epoch 18/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 109.4004 - val_loss: 73.0377\n",
            "Epoch 19/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 84.7919 - val_loss: 55.4323\n",
            "Epoch 20/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 91.9964 - val_loss: 55.8533\n",
            "Epoch 21/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 76.8577 - val_loss: 47.6653\n",
            "Epoch 22/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 82.2582 - val_loss: 45.9067\n",
            "Epoch 23/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 70.0957 - val_loss: 44.6309\n",
            "Epoch 24/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 70.4806 - val_loss: 42.6487\n",
            "Epoch 25/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 72.7143 - val_loss: 40.3677\n",
            "Epoch 26/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 56.4553 - val_loss: 39.8466\n",
            "Epoch 27/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 55.3821 - val_loss: 38.2302\n",
            "Epoch 28/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 59.4435 - val_loss: 36.7895\n",
            "Epoch 29/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 52.9786 - val_loss: 38.5670\n",
            "Epoch 30/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 48.6526 - val_loss: 39.2594\n",
            "Epoch 31/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 50.8622 - val_loss: 39.4350\n",
            "Epoch 32/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 52.4340 - val_loss: 36.7882\n",
            "Epoch 33/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 50.4713 - val_loss: 36.5957\n",
            "Epoch 34/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 38.5706 - val_loss: 34.2493\n",
            "Epoch 35/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 40.3991 - val_loss: 34.3749\n",
            "Epoch 36/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 40.1030 - val_loss: 31.5306\n",
            "Epoch 37/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 39.3350 - val_loss: 32.7150\n",
            "Epoch 38/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 37.0972 - val_loss: 33.7557\n",
            "Epoch 39/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 32.8182 - val_loss: 32.7397\n",
            "Epoch 40/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 33.7587 - val_loss: 30.8959\n",
            "Epoch 41/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 30.3741 - val_loss: 28.9837\n",
            "Epoch 42/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 33.4482 - val_loss: 29.2734\n",
            "Epoch 43/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 29.2665 - val_loss: 27.7499\n",
            "Epoch 44/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 28.7456 - val_loss: 28.8850\n",
            "Epoch 45/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 27.2256 - val_loss: 26.7590\n",
            "Epoch 46/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 30.5482 - val_loss: 27.3641\n",
            "Epoch 47/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 27.9876 - val_loss: 31.0481\n",
            "Epoch 48/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 28.7952 - val_loss: 27.1178\n",
            "Epoch 49/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 29.8883 - val_loss: 26.9693\n",
            "Epoch 50/50\n",
            "288/288 [==============================] - 3s 9ms/sample - loss: 28.3313 - val_loss: 29.0179\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f459f5d7fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPZCeznigBrz"
      },
      "source": [
        "### Evaluando el performance del modelo en test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGA_toh-G_1S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e8c5f3bb-5eea-4a66-986f-34920d68fcd5"
      },
      "source": [
        "# Predicciones en test\n",
        "print(\"Predicciones...\")\n",
        "preds = model.predict([testAttrX, testImagesX])\n",
        "\n",
        "# calcular el error (entre lo predicho y lo esperado)\n",
        "diff = preds.flatten() - testY\n",
        "percentDiff = (diff / testY) * 100\n",
        "absPercentDiff = np.abs(percentDiff)\n",
        "\n",
        "# calcular el error medio y su std\n",
        "mean = np.mean(absPercentDiff)\n",
        "std = np.std(absPercentDiff)\n",
        "\n",
        "# resultados finales\n",
        "print(\"Precio medio: {}. STD: {}\".format(df[\"price\"].mean(),df[\"price\"].std()))\n",
        "print(\"[INFO] mean: {:.2f}%, std: {:.2f}\".format(mean, std))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicciones...\n",
            "Precio medio: 527956.125. STD: 479979.80059985846\n",
            "[INFO] mean: 29.02%, std: 33.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUAv4idMHOwF"
      },
      "source": [
        "#### Ejercicios\n",
        "\n",
        "- Calcular la misma métrica para el modelo MLP solamente\n",
        " - ¿Obtenemos mejores o peores resultados sin las imágenes?\n",
        "- Data augmentation para incrementar los data points (¡pocos!)\n",
        "- Visualizar los filtros y las activaciones máximas del modelo CNN\n",
        " - ¿Se está utilizando de forma efectiva?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpaLBlQthJNj"
      },
      "source": [
        "### *Keys and Tricks*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nrLT5LagpTl"
      },
      "source": [
        "- Creación de un dataset propio a partir de imágenes en la red:\n",
        "https://docs.microsoft.com/en-us/azure/cognitive-services/bing-image-search/quickstarts/python\n",
        "\n",
        "- Custom data generator para la lectura de imágenes/datos:\n",
        "https://towardsdatascience.com/implementing-custom-data-generators-in-keras-de56f013581c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2w7gWaFh2Wr"
      },
      "source": [
        "# Empleando la functional API para el desarrollo de una residual CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIFarnV0DfMz"
      },
      "source": [
        "# Definition of the CNN with residual connections\n",
        "NB_Antennas = 16\n",
        "nn_input  = Input((Nb_Antennas,924,2))\n",
        "nn_input_shortcut = nn_input\n",
        "\n",
        "# 1st RESIDUAL BLOCK\n",
        "nn_output = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(nn_input)\n",
        "nn_output = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(nn_output)\n",
        "nn_output = Conv2D(32, (3, 3), padding=\"same\")(nn_output)\n",
        "nn_input_shortcut = Conv2D(32, (3, 3), padding=\"same\")(nn_input_shortcut)\n",
        "nn_output = Add()([nn_output, nn_input_shortcut])\n",
        "nn_output = Activation('relu')(nn_output)\n",
        "nn_output = AveragePooling2D(pool_size=(1, 4))(nn_output)\n",
        "nn_output_shortcut = nn_output\n",
        "\n",
        "# 2nd RESIDUAL BLOCK\n",
        "nn_output = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(nn_output)\n",
        "nn_output = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(nn_output)\n",
        "nn_output = Conv2D(32, (3, 3), padding=\"same\")(nn_output)\n",
        "nn_output_shortcut = Conv2D(32, (3, 3), padding=\"same\")(nn_output_shortcut)\n",
        "nn_output = Add()([nn_output, nn_output_shortcut])\n",
        "nn_output = Activation('relu')(nn_output)\n",
        "nn_output = AveragePooling2D(pool_size=(1, 4))(nn_output)\n",
        "\n",
        "# TOP MODEL\n",
        "nn_output = Flatten()(nn_output)\n",
        "nn_output = Dense(128, activation='relu')(nn_output)\n",
        "nn_output = Dense(128, activation='relu')(nn_output)\n",
        "nn_output = Dropout(0.25)(nn_output)\n",
        "nn_output = Dense(128, activation='relu')(nn_output)\n",
        "nn_output = Dropout(0.5)(nn_output)\n",
        "nn_output = Dense(3, activation='linear')(nn_output)\n",
        "nn = Model(inputs=nn_input, outputs=nn_output)\n",
        "nn.compile(optimizer='Adam', loss='mse', metrics=[dist])\n",
        "nn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}