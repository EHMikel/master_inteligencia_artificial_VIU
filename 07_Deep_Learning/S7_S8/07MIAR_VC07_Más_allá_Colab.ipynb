{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DB36wZd_tf-v",
        "y-AG85ARE2rc",
        "c0rGcC-mGcTJ",
        "bcNbPlTkO8gm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcNbPlTkO8gm"
      },
      "source": [
        "# Keras Tuner: Optimización de hiperparámetros\n",
        "\n",
        "Keras Tuner es una librería que ayuda a elegir el conjunto óptimo de hiperparámetros de manera automática. El proceso de seleccionar el conjunto correcto de hiperparámetros para un algoritmo de aprendizaje automático ajuste de hiperparámetros o *hypertuning*.\n",
        "Existen dos tipos de hiperparámetros:\n",
        "- **Hiperparámetros de modelo**: Influyen en la selección del modelo, como el número y el ancho de las capas ocultas.\n",
        "\n",
        "- **Hiperparámetros de algoritmo**: Influyen en la velocidad y la calidad del algoritmo de aprendizaje, p.ejem. la tasa de aprendizaje para el descenso de gradiente estocástico (SGD) y el número de vecinos más cercanos para un clasificador KNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VecTRr7cqRK"
      },
      "source": [
        "### Instalamos Keras Tuner y cargamos dataset fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocAn6rVfO73h"
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ3ps2xFQV2w"
      },
      "source": [
        "!pip install -q -U keras-tuner\n",
        "import kerastuner as kt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8b8SYYYQ0aj"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(img_train, label_train), (img_test, label_test) = fashion_mnist.load_data()\n",
        "# Normalize pixel values between 0 and 1\n",
        "img_train = img_train.astype('float32') / 255.0\n",
        "img_test = img_test.astype('float32') / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmNZM7xqc8M5"
      },
      "source": [
        "### Creamos la función que define la topología de red y compila el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5POMBtCQ59Y"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "def model_builder(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
        "  model.add(Dense(units = hp_units, activation = 'relu'))\n",
        "  model.add(Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer = Adam(learning_rate = hp_learning_rate),\n",
        "                loss = SparseCategoricalCrossentropy(from_logits = True),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "716ZJhsvdvsI"
      },
      "source": [
        "### Instanciamos el objeto optimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybpP9msWQ9Bt"
      },
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective = 'val_accuracy',\n",
        "                     max_epochs = 10,\n",
        "                     factor = 3,\n",
        "                     directory = 'my_dir',\n",
        "                     project_name = 'intro_to_kt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p54zfl5Tdb6Q"
      },
      "source": [
        "### Callback para limpiar las salidas de los entrenamientos al finalizar cada paso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__-KD5y4RAeB"
      },
      "source": [
        "import tensorflow as tf\n",
        "import IPython\n",
        "\n",
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhdnWjTudlwo"
      },
      "source": [
        "### Llevamos a cabo la optimización de hiperparámetros y nos quedamos con el mejor resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roupZB05RD5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f27267-c8fb-446e-b87d-2db498251d1c"
      },
      "source": [
        "tuner.search(img_train, label_train, epochs = 10, validation_data = (img_test, label_test), callbacks = [ClearTrainingOutput()])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 01m 23s]\n",
            "val_accuracy: 0.8773000240325928\n",
            "\n",
            "Best val_accuracy So Far: 0.8930000066757202\n",
            "Total elapsed time: 00h 16m 16s\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 480 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "655MPneNfaey"
      },
      "source": [
        "# MLflow\n",
        "Se trata de una plataforma *open source* para la gestión del ciclo de vida de un modelo de *machine learning*. MLflow ofrece cuatro componentes:\n",
        "- ***MLflow Tracking***: Almacenamiento inteligente y monitorización de experimentos (código, datos, configuración y resultados).\n",
        "- ***MLflow Projects***: Paquete de código que permite reproducir cualquier formato de código en cualquier plataforma de trabajo.\n",
        "- ***MLflow Models***: Puesta en marcha de modelo en producción en diversos entornos de servicios.\n",
        "- ***Model Registry***: Almacena, anota, descubre y gestiona modelos en un repositorio centralizado.\n",
        "\n",
        "Demos un paseo por la documentación y ejemplos de la librería: https://mlflow.org/"
      ]
    }
  ]
}