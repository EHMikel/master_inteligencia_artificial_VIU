{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":475,"status":"ok","timestamp":1636111099447,"user":{"displayName":"Adrian Colomer Granero","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01358379493934063214"},"user_tz":-60},"id":"YjffpGpwzkxO","outputId":"4fa79484-4f08-41bb-e674-1601b7473405"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","convolutional_autoencoder.py  __pycache__\t  utils.py\n","my_data_generator.py\t      training_CAE.ipynb\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')\n","# !ls '/content/drive/MyDrive/07MIAR_PracticaObservacional/code/'\n","\n","# # para añadir un directorio de trabajo y poder importar las clases y funciones personalizadads\n","# import sys\n","# sys.path.append('/content/drive/MyDrive/07MIAR_PracticaObservacional/code/')"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":380,"status":"ok","timestamp":1636111259058,"user":{"displayName":"Adrian Colomer Granero","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01358379493934063214"},"user_tz":-60},"id":"rQfSy1kWz6Nj"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'skimage'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\Users\\plane\\OneDrive\\Escritorio\\COMPUTING SCIENCE\\MASTER Inteligencia artificial\\07_Deep_Learning\\practica_observacional\\training_CAE.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/plane/OneDrive/Escritorio/COMPUTING%20SCIENCE/MASTER%20Inteligencia%20artificial/07_Deep_Learning/practica_observacional/training_CAE.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/plane/OneDrive/Escritorio/COMPUTING%20SCIENCE/MASTER%20Inteligencia%20artificial/07_Deep_Learning/practica_observacional/training_CAE.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/plane/OneDrive/Escritorio/COMPUTING%20SCIENCE/MASTER%20Inteligencia%20artificial/07_Deep_Learning/practica_observacional/training_CAE.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmy_data_generator\u001b[39;00m \u001b[39mimport\u001b[39;00m DataGenerator\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/plane/OneDrive/Escritorio/COMPUTING%20SCIENCE/MASTER%20Inteligencia%20artificial/07_Deep_Learning/practica_observacional/training_CAE.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconvolutional_autoencoder\u001b[39;00m \u001b[39mimport\u001b[39;00m ConvAutoencoder\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/plane/OneDrive/Escritorio/COMPUTING%20SCIENCE/MASTER%20Inteligencia%20artificial/07_Deep_Learning/practica_observacional/training_CAE.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m save_reconstructed_images, create_environment, create_json\n","File \u001b[1;32mc:\\Users\\plane\\OneDrive\\Escritorio\\COMPUTING SCIENCE\\MASTER Inteligencia artificial\\07_Deep_Learning\\practica_observacional\\my_data_generator.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m img_to_array\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image                                           \u001b[39m# PARA CARGAR IMAGENES\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m resize                            \u001b[39m# PARA TRANSFORMAR LA IMAGEN\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# In[4]:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[39m# SE CONSIGUE UN GENERADOR DE DATOS PROPIO\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDataGenerator\u001b[39;00m(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mSequence):\n\u001b[0;32m     20\u001b[0m     \n\u001b[0;32m     21\u001b[0m     \u001b[39m# EL CONSTRUCTOR \u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"]}],"source":["# Imports necesarios\n","import tensorflow as tf\n","import pandas as pd\n","from my_data_generator import DataGenerator\n","from convolutional_autoencoder import ConvAutoencoder\n","from utils import save_reconstructed_images, create_environment, create_json\n","from tensorflow.keras.models import load_model\n","import os\n","import numpy as np\n","import cv2"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":549,"status":"ok","timestamp":1636111797051,"user":{"displayName":"Adrian Colomer Granero","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01358379493934063214"},"user_tz":-60},"id":"g-M-MW5y0qBh"},"outputs":[],"source":["#Hyper-parameters\n","input_dim = (128, 128, 1)                     # las dimensiones de entrada\n","encoder_conv_filters = [32, 64, 64, 64]       # el numero de mapas de activacion en cada bloque convolucional\n","encoder_conv_kernel_size = [3, 3, 3, 3]       # las dimensiones de los kernels de cada bloque convolucional\n","encoder_conv_strides = [2, 2, 2, 2]           # los strides de cada bloque conv\n","decoder_conv_t_filters = [64, 64, 32, 1]      # filtros de cada bloque convolucional de decoder, son inversos a los anteriores\n","decoder_conv_t_kernel_size = [3, 3, 3, 3]     # tamaño de los kernels\n","decoder_conv_t_strides = [2, 2, 2, 2]         # los strides del decoer\n","\n","# habre una sesion de tensorflow\n","sess = tf.function()                          \n","z_dim = 200             # dimesniones del espacio latente\n","lr = 0.0005             # el learning_rate\n","batch_size = 8          # tamaño de lotes de entrenamiento\n","epochs = 50             # número de epocas\n","r_loss_factor = 0.4     # factor de reconstruccion\n","is_training = True"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":382,"status":"ok","timestamp":1636112476077,"user":{"displayName":"Adrian Colomer Granero","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01358379493934063214"},"user_tz":-60},"id":"VENem6Tk4d04"},"outputs":[],"source":["base_folder = \"/content/drive/MyDrive/07MIAR_PracticaObservacional/\"\n","#I/O paths\n","# mapea las carpetas donde va a ir guardando cositas\n","run_folders = {\"tsv_path\":      base_folder + \"data/partition.csv\", \n","               \"data_path\":     base_folder + \"data/images/\", \n","               \"model_path\":    base_folder + \"data/Models/\", \n","               \"results_path\":  base_folder + \"data/Results/\", \n","               \"log_filename\":  base_folder + \"data/Results/log/CAE.log\"\n","               }"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":1002,"status":"ok","timestamp":1636112481193,"user":{"displayName":"Adrian Colomer Granero","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01358379493934063214"},"user_tz":-60},"id":"j2nDQ_Dt5Wm1"},"outputs":[],"source":["# Creando el entramado de directorios\n","create_environment(run_folders)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":467,"status":"ok","timestamp":1636112611658,"user":{"displayName":"Adrian Colomer Granero","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01358379493934063214"},"user_tz":-60},"id":"OYNq9GBU3McT"},"outputs":[],"source":["# pasa los parametros en un diccionario y luego los pasa a json\n","hyperparameters = {\"input_dim\":                  input_dim, \n","                   \"encoder_conv_filters\":       encoder_conv_filters, \n","                   \"encoder_conv_kernel_size\":   encoder_conv_kernel_size, \n","                   \"encoder_conv_strides\":       encoder_conv_strides, \n","                   \"decoder_conv_t_filters\":     decoder_conv_t_filters, \n","                   \"decoder_conv_t_kernel_size\": decoder_conv_t_kernel_size, \n","                   \"decoder_conv_t_strides\":     decoder_conv_t_strides, \n","                   \"z_dim\":                      z_dim, \n","                   \"lr\":                         lr, \n","                   \"batch_size\":                 batch_size, \n","                   \"epochs\":                     epochs, \n","                   \"r_loss_factor\":              r_loss_factor, \n","                   \"opt\":                        \"Adam\", \n","                   \"loss_function\":              \"mse\",\n","                   \"data_path\":                  run_folders[\"data_path\"]\n","                   }\n","create_json(hyperparameters, run_folders)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1437869,"status":"ok","timestamp":1636115397085,"user":{"displayName":"Adrian Colomer Granero","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01358379493934063214"},"user_tz":-60},"id":"YsXtEphD8S0i","outputId":"f11ed962-80f5-4f7b-ee28-1c28934f31e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","encoder_input (InputLayer)   [(None, 128, 128, 1)]     0         \n","_________________________________________________________________\n","encoder_conv0 (Conv2D)       (None, 64, 64, 32)        320       \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 64, 64, 32)        128       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","encoder_conv1 (Conv2D)       (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","encoder_conv2 (Conv2D)       (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","encoder_conv3 (Conv2D)       (None, 8, 8, 64)          36928     \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 4096)              0         \n","_________________________________________________________________\n","encoder_output (Dense)       (None, 200)               819400    \n","_________________________________________________________________\n","model_1 (Functional)         (None, 128, 128, 1)       915905    \n","=================================================================\n","Total params: 1,828,873\n","Trainable params: 1,828,425\n","Non-trainable params: 448\n","_________________________________________________________________\n","None\n","[INFO]: Training\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","44/44 [==============================] - 398s 9s/step - loss: 0.0441 - val_loss: 0.0518\n","\n","Epoch 00001: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 2/50\n","44/44 [==============================] - 19s 423ms/step - loss: 0.0194 - val_loss: 0.0391\n","\n","Epoch 00002: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 3/50\n","44/44 [==============================] - 19s 422ms/step - loss: 0.0140 - val_loss: 0.0395\n","\n","Epoch 00003: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 4/50\n","44/44 [==============================] - 19s 424ms/step - loss: 0.0118 - val_loss: 0.0374\n","\n","Epoch 00004: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 5/50\n","44/44 [==============================] - 19s 423ms/step - loss: 0.0095 - val_loss: 0.0351\n","\n","Epoch 00005: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 6/50\n","44/44 [==============================] - 19s 428ms/step - loss: 0.0094 - val_loss: 0.0282\n","\n","Epoch 00006: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 7/50\n","44/44 [==============================] - 19s 422ms/step - loss: 0.0084 - val_loss: 0.0255\n","\n","Epoch 00007: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 8/50\n","44/44 [==============================] - 19s 424ms/step - loss: 0.0082 - val_loss: 0.0255\n","\n","Epoch 00008: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 9/50\n","44/44 [==============================] - 19s 428ms/step - loss: 0.0072 - val_loss: 0.0180\n","\n","Epoch 00009: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 10/50\n","44/44 [==============================] - 19s 425ms/step - loss: 0.0068 - val_loss: 0.0155\n","\n","Epoch 00010: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 11/50\n","44/44 [==============================] - 19s 429ms/step - loss: 0.0065 - val_loss: 0.0113\n","\n","Epoch 00011: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 12/50\n","44/44 [==============================] - 19s 430ms/step - loss: 0.0060 - val_loss: 0.0085\n","\n","Epoch 00012: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 13/50\n","44/44 [==============================] - 19s 426ms/step - loss: 0.0060 - val_loss: 0.0082\n","\n","Epoch 00013: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 14/50\n","44/44 [==============================] - 19s 428ms/step - loss: 0.0058 - val_loss: 0.0062\n","\n","Epoch 00014: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 15/50\n","44/44 [==============================] - 19s 430ms/step - loss: 0.0059 - val_loss: 0.0066\n","\n","Epoch 00015: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 16/50\n","44/44 [==============================] - 19s 429ms/step - loss: 0.0056 - val_loss: 0.0062\n","\n","Epoch 00016: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 17/50\n","44/44 [==============================] - 19s 427ms/step - loss: 0.0056 - val_loss: 0.0055\n","\n","Epoch 00017: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 18/50\n","44/44 [==============================] - 19s 427ms/step - loss: 0.0050 - val_loss: 0.0057\n","\n","Epoch 00018: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 19/50\n","44/44 [==============================] - 19s 427ms/step - loss: 0.0053 - val_loss: 0.0065\n","\n","Epoch 00019: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 20/50\n","44/44 [==============================] - 19s 421ms/step - loss: 0.0054 - val_loss: 0.0056\n","\n","Epoch 00020: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 21/50\n","44/44 [==============================] - 19s 426ms/step - loss: 0.0048 - val_loss: 0.0052\n","\n","Epoch 00021: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 22/50\n","44/44 [==============================] - 19s 426ms/step - loss: 0.0046 - val_loss: 0.0052\n","\n","Epoch 00022: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 23/50\n","44/44 [==============================] - 19s 425ms/step - loss: 0.0043 - val_loss: 0.0050\n","\n","Epoch 00023: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 24/50\n","44/44 [==============================] - 19s 431ms/step - loss: 0.0042 - val_loss: 0.0053\n","\n","Epoch 00024: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 25/50\n","44/44 [==============================] - 19s 433ms/step - loss: 0.0043 - val_loss: 0.0058\n","\n","Epoch 00025: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 26/50\n","44/44 [==============================] - 19s 430ms/step - loss: 0.0041 - val_loss: 0.0050\n","\n","Epoch 00026: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 27/50\n","44/44 [==============================] - 19s 427ms/step - loss: 0.0040 - val_loss: 0.0050\n","\n","Epoch 00027: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 28/50\n","44/44 [==============================] - 19s 430ms/step - loss: 0.0041 - val_loss: 0.0050\n","\n","Epoch 00028: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 29/50\n","44/44 [==============================] - 19s 431ms/step - loss: 0.0040 - val_loss: 0.0049\n","\n","Epoch 00029: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 30/50\n","44/44 [==============================] - 19s 431ms/step - loss: 0.0040 - val_loss: 0.0051\n","\n","Epoch 00030: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 31/50\n","44/44 [==============================] - 19s 428ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 00031: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 32/50\n","44/44 [==============================] - 19s 421ms/step - loss: 0.0038 - val_loss: 0.0049\n","\n","Epoch 00032: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 33/50\n","44/44 [==============================] - 19s 429ms/step - loss: 0.0038 - val_loss: 0.0051\n","\n","Epoch 00033: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 34/50\n","44/44 [==============================] - 19s 428ms/step - loss: 0.0035 - val_loss: 0.0051\n","\n","Epoch 00034: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 35/50\n","44/44 [==============================] - 19s 424ms/step - loss: 0.0036 - val_loss: 0.0051\n","\n","Epoch 00035: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 36/50\n","44/44 [==============================] - 19s 428ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 00036: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 37/50\n","44/44 [==============================] - 19s 429ms/step - loss: 0.0034 - val_loss: 0.0051\n","\n","Epoch 00037: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 38/50\n","44/44 [==============================] - 19s 427ms/step - loss: 0.0035 - val_loss: 0.0049\n","\n","Epoch 00038: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 39/50\n","44/44 [==============================] - 19s 423ms/step - loss: 0.0033 - val_loss: 0.0049\n","\n","Epoch 00039: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 40/50\n","44/44 [==============================] - 19s 431ms/step - loss: 0.0032 - val_loss: 0.0048\n","\n","Epoch 00040: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 41/50\n","44/44 [==============================] - 19s 434ms/step - loss: 0.0032 - val_loss: 0.0049\n","\n","Epoch 00041: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 42/50\n","44/44 [==============================] - 19s 430ms/step - loss: 0.0031 - val_loss: 0.0048\n","\n","Epoch 00042: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 43/50\n","44/44 [==============================] - 19s 434ms/step - loss: 0.0032 - val_loss: 0.0049\n","\n","Epoch 00043: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 44/50\n","44/44 [==============================] - 19s 433ms/step - loss: 0.0030 - val_loss: 0.0047\n","\n","Epoch 00044: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 45/50\n","44/44 [==============================] - 19s 431ms/step - loss: 0.0029 - val_loss: 0.0048\n","\n","Epoch 00045: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 46/50\n","44/44 [==============================] - 19s 424ms/step - loss: 0.0030 - val_loss: 0.0048\n","\n","Epoch 00046: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 47/50\n","44/44 [==============================] - 19s 429ms/step - loss: 0.0028 - val_loss: 0.0052\n","\n","Epoch 00047: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 48/50\n","44/44 [==============================] - 19s 428ms/step - loss: 0.0029 - val_loss: 0.0055\n","\n","Epoch 00048: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 49/50\n","44/44 [==============================] - 19s 427ms/step - loss: 0.0031 - val_loss: 0.0050\n","\n","Epoch 00049: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n","Epoch 50/50\n","44/44 [==============================] - 19s 426ms/step - loss: 0.0028 - val_loss: 0.0047\n","\n","Epoch 00050: saving model to /content/drive/MyDrive/07MIAR_PracticaObservacional/data/Models/exp_0001/weights/CAE_weights.h5\n"]}],"source":["# Fase de entrenamiento\n","if is_training:\n","\n","  # Carga de datos\n","  df_pneumo_2d = pd.read_csv(run_folders[\"tsv_path\"], sep=\";\")             # crea el dataframe, con separador de puntos y comas\n","  df_pneumo_2d.columns = ['ImageID', 'Partition', 'Class']                 # asigna columnas como header\n","  data_filter = df_pneumo_2d['Partition']=='train'                         # separa los datos de train\n","\n","  # Cargador de datos training\n","  data_flow_train = DataGenerator(df_pneumo_2d[data_filter],               # se pasa el dataframe filtrado\n","                                  input_dim[1],                            # ancho\n","                                  input_dim[0],                            # alto \n","                                  input_dim[2],                            # canales\n","                                  batch_size=batch_size,                   # tamaño del lote\n","                                  path_to_img=run_folders[\"data_path\"],    # el path de la data\n","                                  shuffle = True)                          # mezlar: si\n","  \n","  # Cargador de datos validation\n","  data_filter = df_pneumo_2d['Partition']=='val'                           # datos de validación\n","  data_flow_val = DataGenerator(df_pneumo_2d[data_filter],                 # el dataframe\n","                                  input_dim[1], \n","                                  input_dim[0], \n","                                  input_dim[2], \n","                                  batch_size=batch_size, \n","                                  path_to_img=run_folders[\"data_path\"],\n","                                  )                                        # esta vez no se mezcla por que shuffle solo interesa en train\n","  \n","  # Creando el CAE\n","  my_CAE = ConvAutoencoder(input_dim,                         # se pasan los dimensiones\n","                           encoder_conv_filters,              # filtros de ENCODER\n","                           encoder_conv_kernel_size,          # tamaño del kernel en el ENCODER\n","                           encoder_conv_strides,              # los pasos del ENCODER\n","                           decoder_conv_t_filters,            # fitlros de DECODER\n","                           decoder_conv_t_kernel_size,        # kernels de DECODER\n","                           decoder_conv_t_strides,            # el paso de DECODER\n","                           z_dim)                             # dimensiones del espacio latente\n","  \n","  # Construyendo arquitectura\n","  my_CAE.build(use_batch_norm=True,         # utiliza batch normalization\n","              use_dropout=False,            # no usa dropout\n","              VCAE=False)                   # utiliza la version original osea un AUTO ENCODER NORMAL\n","  \n","  print(my_CAE.model.summary())             # MUESTRA EL RESULMEN\n","\n","  # Compilando el CAE\n","  my_CAE.compile(learning_rate=lr, r_loss_factor=r_loss_factor)     \n","\n","  # Entrenando el CAE\n","  steps_per_epoch = len(data_flow_train)\n","  H = my_CAE.train(data_flow_train, \n","                   epochs, \n","                   steps_per_epoch, \n","                   data_flow_val, \n","                   run_folders)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11701,"status":"ok","timestamp":1636115666831,"user":{"displayName":"Adrian Colomer Granero","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01358379493934063214"},"user_tz":-60},"id":"TXnporZz_-2Y","outputId":"95389432-0658-4eb4-d7a9-9cdee3af500b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","encoder_input (InputLayer)   [(None, 128, 128, 1)]     0         \n","_________________________________________________________________\n","encoder_conv0 (Conv2D)       (None, 64, 64, 32)        320       \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 64, 64, 32)        128       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","encoder_conv1 (Conv2D)       (None, 32, 32, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","encoder_conv2 (Conv2D)       (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","encoder_conv3 (Conv2D)       (None, 8, 8, 64)          36928     \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 4096)              0         \n","_________________________________________________________________\n","encoder_output (Dense)       (None, 200)               819400    \n","_________________________________________________________________\n","model_1 (Functional)         (None, 128, 128, 1)       915905    \n","=================================================================\n","Total params: 1,828,873\n","Trainable params: 1,828,425\n","Non-trainable params: 448\n","_________________________________________________________________\n","None\n","(8, 128, 128, 1)\n"]}],"source":["is_training = True\n","# Carga de datos\n","df_pneumo_2d = pd.read_csv(run_folders[\"tsv_path\"], sep=\";\")\n","df_pneumo_2d.columns = ['ImageID', 'Partition', 'Class']\n","data_filter = df_pneumo_2d['Partition']=='test'\n","# Cargador de datos training\n","data_flow_test = DataGenerator(df_pneumo_2d[data_filter], \n","                                input_dim[1], \n","                                input_dim[0], \n","                                input_dim[2], \n","                                batch_size=batch_size, \n","                                path_to_img=run_folders[\"data_path\"],\n","                                shuffle = False)\n","\n","if not is_training:\n","  my_CAE = ConvAutoencoder.load_model(run_folders)          # cargar el modelo     \n","\n","print(my_CAE.model.summary())\n","\n","example_batch = data_flow_test.__getitem__(index=0)\n","example_images = example_batch[0]\n","\n","y_pred = my_CAE.model.predict(example_images)\n","print(y_pred.shape)\n","\n","save_reconstructed_images(example_images, y_pred, run_folders)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNUtAu3XGNjmbd6HFjTnat0","collapsed_sections":[],"mount_file_id":"1hs3-lRJTd2DnNQxEe557Xd8rTMSkvrP9","name":"training_CAE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.11"}},"nbformat":4,"nbformat_minor":0}
