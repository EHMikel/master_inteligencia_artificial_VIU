{"loss": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "mae": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "mean_q": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "mean_eps": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "episode_reward": [1.0, 0.0, 4.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0], "nb_episode_steps": [203, 126, 313, 149, 130, 209, 141, 216, 131], "nb_steps": [203, 329, 642, 791, 921, 1130, 1271, 1487, 1618], "episode": [0, 1, 2, 3, 4, 5, 6, 7, 8], "duration": [3.819000899999992, 0.7151085000000421, 1.661843699999963, 0.7969935000000987, 0.7558132999999998, 1.1353524999999536, 0.7672238000000107, 1.2010751000000255, 0.7136304999999084]}